# ğŸ“š Proyecto Pipeline de Libros: Scraper y Enriquecimiento

## âœ¨ DescripciÃ³n

Este proyecto permite extraer datos de libros desde **Goodreads** mediante scraping y enriquecerlos con informaciÃ³n de la **API de Google Books**. Posteriormente, los datos se unifican, normalizan y deduplican para generar un dataset final listo para anÃ¡lisis o carga en un sistema.

El flujo completo consiste en:

1. ğŸ•¸ï¸ Scraping de Goodreads para obtener tÃ­tulos, autores, rating y URLs de los libros.
2. ğŸ” ExtracciÃ³n detallada de ISBN-10 e ISBN-13 desde las pÃ¡ginas de Goodreads.
3. âš¡ Enriquecimiento con la API de Google Books, incluyendo precios, categorÃ­as y otros metadatos.
4. ğŸ› ï¸ IntegraciÃ³n y normalizaciÃ³n de datos.
5. ğŸ§¹ DeduplicaciÃ³n y priorizaciÃ³n de ISBN10 de Google Books.
6. ğŸ“¦ GeneraciÃ³n de artefactos finales:

   * `dim_book.parquet`: tabla unificada de libros.
   * `book_source_detail.parquet`: detalle por fuente de cada registro.
   * `quality_metrics.json`: mÃ©tricas de calidad.
   * `schema.md`: documentaciÃ³n de esquema.

## ğŸ“ Requisitos

* Python >= 3.10
* Google Chrome para Selenium
* Chromedriver compatible con tu versiÃ³n de Chrome
* Claves de API:

  * `GOOGLE_BOOKS_API_KEY` en un archivo `.env`
* Variables opcionales:

  * `USER_AGENT` â†’ user agent para peticiones HTTP
  * `RATE_LIMIT_SECONDS` â†’ tiempo de espera entre peticiones (default 0.8s)
  * `SEARCH_QUERY` â†’ tÃ©rmino de bÃºsqueda en Goodreads
  * `MAX_BOOKS` â†’ mÃ¡ximo nÃºmero de libros a extraer

Dependencias Python:

* requests ğŸ“
* tqdm â³
* pandas ğŸ¼
* numpy ğŸ”¢
* pyarrow ğŸ“Š
* python-dotenv ğŸŒ¿
* selenium ğŸ¤–

## âš™ï¸ InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv .venv
# Activar entorno
# Windows
.venv\Scripts\activate
# Linux / macOS
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Copiar el archivo .env
copy .env.example .env
```

## ğŸ—‚ï¸ Estructura del proyecto

```
project_root/
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ scraper_goodreads.py         # ğŸ•¸ï¸ Scraper de Goodreads
â”‚   â”œâ”€ enrich_google_books.py       # âš¡ Enriquecimiento con Google Books API
â”‚   â”œâ”€ integrate_pipeline.py        # ğŸ› ï¸ IntegraciÃ³n, limpieza y deduplicaciÃ³n
â”‚   â”œâ”€ utils_quality.py             # ğŸ“Š CÃ¡lculo de mÃ©tricas de calidad
â”‚   â””â”€ utils_isbn.py                # ğŸ”¢ ValidaciÃ³n de ISBN13
â”‚
â”œâ”€ landing/                         # ğŸ“¥ Archivos crudos
â”‚   â”œâ”€ goodreads_books.json
â”‚   â””â”€ googlebooks_books.csv
â”‚
â”œâ”€ standard/                        # âœ… Datos finales procesados
â”‚   â”œâ”€ dim_book.parquet
â”‚   â””â”€ book_source_detail.parquet
â”‚
â”œâ”€ docs/                            # ğŸ“‘ DocumentaciÃ³n y mÃ©tricas
â”‚   â”œâ”€ quality_metrics.json
â”‚   â””â”€ schema.md
â”‚
â”œâ”€ staging/                         # ğŸ› ï¸ Archivos intermedios
â”œâ”€ .env                             # ğŸ”‘ Variables de entorno (API keys)
â””â”€ requirements.txt
```

## ğŸš€ Uso

1. Configurar `.env` con tus claves y parÃ¡metros:

```
GOOGLE_BOOKS_API_KEY=tu_api_key
USER_AGENT=books-pipeline-bot/1.0
RATE_LIMIT_SECONDS=0.8
SEARCH_QUERY=animals
MAX_BOOKS=15
```

2. Ejecutar scraper de Goodreads:

```bash
python src/scraper_goodreads.py
```

GenerarÃ¡ `landing/goodreads_books.json`.

3. Ejecutar enriquecimiento con Google Books API:

```bash
python src/enrich_google_books.py
```

GenerarÃ¡ `landing/googlebooks_books.csv`.

4. Ejecutar integraciÃ³n y deduplicaciÃ³n:

```bash
python src/integrate_pipeline.py
```

GenerarÃ¡:

* `standard/dim_book.parquet` ğŸ“¦
* `standard/book_source_detail.parquet` ğŸ“¦
* `docs/quality_metrics.json` ğŸ“Š
* `docs/schema.md` ğŸ“‘

